# Cleaned

## Possible experiment:
- train + test phase of original experiments
- do we get test performance that humans get?
- need alternative model w/ different predictions:
    - e.g. daniel zoran's which does spatial abstraction
- can the *theory* predict when humans fail? 
    - what are minimal changes to train + test that break the architecture?
        - do humans fail when model fails?
        - if not, is it because model is missing something theory requires?

## Concerns:
- need data setting where humans struggle to see if RL struggles similarly


---


# Messy



If humans are transferring this schemata:
- should transfer in way getting wins in agent



Train + test stage:

    training: experiences that model gets
    test: do we get immediate transfer


    need alternative models that make different kinds of predictions:
        - other architecture that does pretty well: e.g. daniel zoran's


What are minimal changes to train + test so that architecture doesn't do well?
    - do humans fail where model fails
    - expose where model doesn't do well and humans don't do as well


Are cases where architecture breaks down:
    - architecture not living up or perceptual schemata don't transfer?
    - do I have theory independent of implementation?
        yes. implementation is not platonic ideal.
    - am I testing theory or model?
        currently thinking model.

when do humans not do well because schemata don't do well:
    need to predict when humans fail same way schemata fail


Think about:
    what does theory predict?



    theory formation: look at what humans do
    theory testing: no more. what does model predict?




- bonobos and chimps are interacting with env
- require coordination and collaboration with other agents
- we're building succession of deep RL models with same task as interface
- now collecting data on simple tasks w/ apes
- now learning how to chase bunnies
- Q1: do they antipate bunny movement
- plan:
    - train models on 2 settings
        - which one best captures ape data


- Sean:
    - getting feet wet building deep Rl agents


