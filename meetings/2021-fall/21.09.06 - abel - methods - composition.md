
# Cleaned

A perceptual schema is an abstract representation of a set of observation-action sequences that focuses on arbitrary [task-relevant] fragments of the environment

## What do we mean by task-driven learning of the representation?
1. we're using the representation to predict action and reward
2. some representation of task (which encodes part of the task structure or hints at the abstract pieces the agent wants to learn) is given as input to the function

## what are good abstractions to latch onto?
- we focus on multi-task learning setting though this could be generalized to a continual learning set-up without explicit task boundaries. we leave this extension for future work.
- a good schema (abstraction) latches onto observation-action sequences which *repeat* in agent's experience maximizing reward. 
    - we aim to learn schemata that enable predicting which actions maximize reward. 
        - these schemata should enable their recognition in novel ecological situations
            - e.g., novel orders (ballet - sequential, playroom, keybox)
            - e.g., novel joint appearance (ballet - parallel)
            - e.g., novel schemata history lengths (ballet-sequential, Keybox)
    - we hypothesize that episodes without reward serve as negative examples for what *do not* correspond to perceptual schema


- want to learn attention over observations that enables representation predicting the actions which maximize reward. 


## why does the implementation you think about help with this?
1. structured RNN: encourages specialization of TROFs over subsets of training data
    2. message-passing enables coordination of what they specialize on
2. feature-attention over spatio-temporal features: enables TROF to attend to subsets of observation-action sequences for extended period of time




## Suggestion: come up with simple example that fleshes out the mechanisms
- Ballet example is the most obvious one.
- Keybox example is most interesting one.



# Raw

abstract representations of observation-action sequences that focus on arbitrary task-relevant fragments of the environment

Q: what are good abstractions to latch onto?
- repeated structure of perceptual schemata -- sequences of perceptual schema -- manifest across training tasks
- hypothesis: requires multitask learning setting

Train 1: (p1, p1), (p2, p8), (p3, p4)
Train 2: (p2, p1), (p5, p1), (p3, p1)

Task-driven:
    - rep is tailored for task
        - we're using to predict action + value
    - given as input for task
        - ballet + playroom: task input gives hints to abstract pieces
        
Come up with 1 simple running example (maybe more conceptual than experiments) that fleshes out the mechanisms 


What is a good schema? Connect to behavior.
- how does content of schema connect to agent's behavior?
- are schema that pick up on repeated structure, transfer, across tasks, but don't contribute behavior. e.g., consistent noisy tv.

Test2 (playroom: language as task input --> tells you composition you want): novel schema combo (p1, p8) 
Test1 (ballet2d: language as task @end):
  (p1, p8) --> (p1, p8, p5, p2)

Test3 (keybox: goal is *always* move to right until observe key of goal color which is observed in beginning): (p1, p8)
