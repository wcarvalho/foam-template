# Thursday, June 3, 2021


## Perceptual Schemata

* **playroom**
  [x] copy parameters from Felix for word-binding task
  [x] LSTM
    [x] search on {place tasks}
    [x] search w/ pixel-control on {word-binding}
  * Schemata + pixel-control on {word-binding}
    [x] heads={4,8}, schema_dim={128, 256, 512}, hidden_dim={256, 512, 1024}
  * Schemata on {place tasks}
    [x] heads={4,8}, schema_dim={128, 256, 512}, hidden_dim={256, 512, 1024}
  [ ] Schemata on {causal tasks}


* **run ablations**
  [x] [P1-1week] keybox: heads={1, 4, 8}, attention={0,1}
    * run = 1 hr if I get the sizes correct


* ~~**improve put next**~~
  [ ] analyze prior results:
    [ ] separate vs. shared for keybox/putnext (did well??)
    [ ] hard-gate + cost for putnext (did well??)
  [ ] try:
    [ ] transformer:
      [x] dim={64, 32}, join={concat, sum}


* **refactor**
  [ ] structure:
    [ ] models folder
    [ ] base class for structured-recurrent-attention
  [ ] **baselines**
    [ ] [P1-1week] RIMs
    [ ] [P1-1week] ConvLSTM
    [ ] [P2] LSTM: {128, current} <-- show doesn't improve performance 

* **analysis**
  [ ] [P1-1week] activations/norm of (a) heads + (b) "state" for keybox+ballerina
  [ ] using small box (e.g. 5x5 or 6x6), sample as many conditions as possible (should be small)
    [ ] see if each pattern is mapped to its own schema (this can be learned in like 30 minutes)


* **theory**
  [ ] consolidate notes into one cohesive piece (model complexity, pieces, etc.) before meeting with Abel



* **ICLR**
  [ ] putnext: LSTM by itself {128, 256}
  [ ] keybox: LSTM by itself {128, 256, 512}
  [ ] ballerina: LSTM by itself {128, 256, 512}


## Other
* **dissertation fellowships**
  [ ] [fellowships](https://www.cs.cmu.edu/~gradfellowships/): Ford, Microsoft, Apple PhD, JPMorgan Fellowship


* **errands**
  * book flights

* honglak
  * fellowships: people *really* like my deepmind work. I think it'll be a strong paper...
  * how would you feel about me trying to collaborate with people in cognitive science to see if my model's explain human behavior?
  * recurrent-indepdent-mechanisms--> if associate policy with each, maybe lead to emergence of options?


* #schema-example
  * help you learn how to use new maps app (e.g. apple maps) really quickly
  * help you learn to use a new music player (e.g. spotify --> apply music)
  * for both examples, you already know what states are possible more-or-less
    * schemata let's you infer which state you're in quickly